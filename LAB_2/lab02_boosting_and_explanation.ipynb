{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ooxnCzMb8_EX",
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-86e0de040aac317a",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "source": [
    "# <a href=\"https://girafe.ai/\" target=\"_blank\" rel=\"noopener noreferrer\"><img src=\"https://raw.githubusercontent.com/girafe-ai/ml-course/7096a5df4cada5ee651be1e3215c2f7fb8a7e0bf/logo_margin.svg\" alt=\"girafe-ai logo\" width=\"150px\" align=\"left\"></a> [ml-basic course](https://github.com/girafe-ai/ml-course) <a class=\"tocSkip\">\n",
    "\n",
    "# Lab assignment №1, part 2\n",
    "## Gradient boosting on temporal data and feature importances"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wVmAIjhc8_EZ"
   },
   "source": [
    "Today we will work with Gradient Boosting library. It is one of the most popular models these days that shows both great quality and performance.\n",
    "\n",
    "Choises for library are:\n",
    "\n",
    "* [LightGBM](https://github.com/Microsoft/LightGBM) by Microsoft. Handful and fast.\n",
    "* [Catboost](https://github.com/catboost/catboost) by Yandex. Tuned to deal well with categorical features.\n",
    "* [xgboost](https://github.com/dmlc/xgboost) by dlmc. The most famous framework which got very popular on kaggle.\n",
    "\n",
    "**Dataset**\n",
    "\n",
    "By default we will work with widely known [Human Actividy Recognition (HAR) dataset](https://archive.ics.uci.edu/dataset/240/human+activity+recognition+using+smartphones). Data is available at UCI repository.\n",
    "\n",
    "There are available both raw and preprocessed datasets. This time we will use the preprocessed one.\n",
    "Some simple preprocessing is done for you.\n",
    "\n",
    "If you want more interpretable data, you can take [Wine quality dataset](https://archive.ics.uci.edu/dataset/186/wine+quality) (see details below).\n",
    "\n",
    "Your __ultimate target is to get familiar with one of the frameworks above__ and achieve at least 90% accuracy on test dataset and try to get some useful insights on the features the model paid attention to.\n",
    "\n",
    "_Despite the main language of this notebook is English, feel free to write your thoughts in Russian._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aKIlWIa28_Ea"
   },
   "source": [
    "## Part 0. Downloading and preprocessing\n",
    "\n",
    "The preprocessing is done for you. Let's take a look at the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RzcR8MIQ8_Ea",
    "outputId": "b2097ec5-26b7-4c9f-d7c2-f4c753d5853e"
   },
   "outputs": [],
   "source": [
    "# Download and unpack dataset from UCI\n",
    "!wget -nc https://archive.ics.uci.edu/ml/machine-learning-databases/00240/UCI%20HAR%20Dataset.zip\n",
    "!unzip -u \"UCI HAR Dataset.zip\" \"UCI HAR Dataset/train/X_train.txt\" \"UCI HAR Dataset/train/y_train.txt\" \\\n",
    "\"UCI HAR Dataset/test/X_test.txt\" \"UCI HAR Dataset/test/y_test.txt\" \"UCI HAR Dataset/activity_labels.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "q36ECNTq8_Eb"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VXth86nx8_Ec",
    "outputId": "1b0753dd-3f55-402b-a969-832c62370450"
   },
   "outputs": [],
   "source": [
    "X_train = np.genfromtxt(\"UCI HAR Dataset/train/X_train.txt\")\n",
    "y_train = np.genfromtxt(\"UCI HAR Dataset/train/y_train.txt\")\n",
    "print(f\"Train set: {X_train.shape}, {y_train.shape}\")\n",
    "\n",
    "X_test = np.genfromtxt(\"UCI HAR Dataset/test/X_test.txt\")\n",
    "y_test = np.genfromtxt(\"UCI HAR Dataset/test/y_test.txt\")\n",
    "print(f\"Test set: {X_test.shape}, {y_test.shape}\")\n",
    "\n",
    "n_features = X_train.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8PRItnVP8_Ec",
    "outputId": "8c93457a-22ce-4d9a-cd96-b8db9456c09f"
   },
   "outputs": [],
   "source": [
    "activity_labels = {}\n",
    "with open(\"UCI HAR Dataset/activity_labels.txt\", \"r\") as file:\n",
    "    for line in file:\n",
    "        label, name = line.strip().split(\" \")\n",
    "        activity_labels[int(label)] = name\n",
    "\n",
    "activity_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "v0T5ydqw8_Ed"
   },
   "source": [
    "Let's normalize data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gvTZkHd08_Ed"
   },
   "outputs": [],
   "source": [
    "data_mean = X_train.mean(axis=0)\n",
    "data_std = X_train.std(axis=0)\n",
    "\n",
    "X_train = (X_train - data_mean) / data_std\n",
    "X_test = (X_test - data_mean) / data_std"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qK6rJtqO8_Ed"
   },
   "source": [
    "The dataset has some duplicating features. Let's remove them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DlQxyx0F8_Ee"
   },
   "outputs": [],
   "source": [
    "# fmt: off\n",
    "duplicating_columns = (\n",
    "    205, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 231, 244, 257, 507, 520, 533, 546,\n",
    ")\n",
    "# fmt: on\n",
    "\n",
    "duplicating_mask = np.isin(range(n_features), duplicating_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QOSwiTNQ8_Ee",
    "outputId": "9ca05f8c-9fb0-4c18-ac82-6b715d835e7a"
   },
   "outputs": [],
   "source": [
    "X_train_unique = X_train[:, ~duplicating_mask]\n",
    "X_test_unique = X_test[:, ~duplicating_mask]\n",
    "\n",
    "X_train_unique.shape, X_test_unique.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "G4CmrTcV8_Ee"
   },
   "source": [
    "PCA could be useful in this case. E.g."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_xW1hUs88_Ee"
   },
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6g5BhW-O8_Ee",
    "outputId": "3dee5dea-26b6-4697-8a46-213b44d27a35"
   },
   "outputs": [],
   "source": [
    "pca = PCA(0.99)\n",
    "\n",
    "X_train_pca = pca.fit_transform(X_train_unique)\n",
    "X_test_pca = pca.transform(X_test_unique)\n",
    "\n",
    "X_train_pca.shape, X_test_pca.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 467
    },
    "id": "XaaHrRbw8_Ef",
    "outputId": "044f761b-c7c1-4114-a63d-ac4107816dd0"
   },
   "outputs": [],
   "source": [
    "plt.scatter(X_train_pca[:1000, 0], X_train_pca[:1000, 1], c=y_train[:1000])\n",
    "plt.grid()\n",
    "plt.xlabel(\"Principal component 1\")\n",
    "plt.ylabel(\"Principal component 2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 467
    },
    "id": "9XQCwV-F8_Ef",
    "outputId": "fe61ad20-2ad5-4302-a319-2d7b1fca1d22"
   },
   "outputs": [],
   "source": [
    "plt.scatter(X_train_pca[:1000, 3], X_train_pca[:1000, 4], c=y_train[:1000])\n",
    "plt.grid()\n",
    "plt.xlabel(\"Principal component 4\")\n",
    "plt.ylabel(\"Principal component 5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wjUeg8L1F75Z"
   },
   "source": [
    "### Alternative dataset: Wine quality\n",
    "\n",
    "Please, take this dataset if you are sure you can preprocess it yourself and ready to work with it's features and results, so it is done on your risk.\n",
    "\n",
    "However you will have interpretable features which can be analysed with shap in last part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fisOD8F-F--S",
    "outputId": "19b869c3-af26-4d9c-a4e0-e606c6cf4312"
   },
   "outputs": [],
   "source": [
    "!pip install ucimlrepo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fuOW1zS6F_XZ"
   },
   "outputs": [],
   "source": [
    "import ucimlrepo as uci"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "p07MKA9vGCIq",
    "outputId": "8ba30ed7-6637-479d-e5b7-6e98f3b166be"
   },
   "outputs": [],
   "source": [
    "dataset = uci.fetch_ucirepo(id=186)\n",
    "\n",
    "print(dataset.metadata.name, '\\n')\n",
    "print(dataset.metadata.abstract, '\\n')\n",
    "print(dataset.metadata.additional_info.summary, '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-_U8TnNg8_Ef"
   },
   "source": [
    "## Part 1. Fit the model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ARxEImwz8_Ef"
   },
   "source": [
    "Despite optimal parameters (e.g. for xgboost) can be found on the web, we still want you to approximate them by yourself.\n",
    "\n",
    "In this part just check some (3-5) sets of hyperparameters by hand."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KjKl26kbXgpL"
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "P9aY9BrwYKft",
    "outputId": "5ba5be94-616e-4400-da10-06b53de6e9d0"
   },
   "outputs": [],
   "source": [
    "!pip install catboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "71vHYD318_Ef"
   },
   "outputs": [],
   "source": [
    "# Example: https://rpubs.com/burakh/har_xgb\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "from lightgbm import LGBMClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "S4VbggTxXui9"
   },
   "source": [
    "Напишем Функцию для тренировки модели и вывода метрик:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tfumACUvXtsv"
   },
   "outputs": [],
   "source": [
    "def train_and_evaluate(model, X_train, y_train, X_test, y_test):\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "55wS4EfNX8LB"
   },
   "source": [
    "### **LightGBM**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZhH6vWpSYB3k",
    "outputId": "04cbd5ea-1260-4b65-9921-d378ca6644cc"
   },
   "outputs": [],
   "source": [
    "print(\"Testing LightGBM with different hyperparameters:\")\n",
    "\n",
    "lgbm_params_list = [\n",
    "    {\"n_estimators\": 100, \"learning_rate\": 0.1, \"max_depth\": 7, \"random_state\": 42},\n",
    "    {\"n_estimators\": 150, \"learning_rate\": 0.05, \"max_depth\": 9, \"random_state\": 42},\n",
    "    {\"n_estimators\": 200, \"learning_rate\": 0.1, \"max_depth\": 5, \"random_state\": 42},\n",
    "    {\"n_estimators\": 300, \"learning_rate\": 0.05, \"max_depth\": 6, \"random_state\": 42},\n",
    "    {\"n_estimators\": 250, \"learning_rate\": 0.2, \"max_depth\": 4, \"random_state\": 42},\n",
    "]\n",
    "\n",
    "for i, params in enumerate(lgbm_params_list, 1):\n",
    "    print(f\"\\nSet {i}: {params}\")\n",
    "\n",
    "    lgbm_model = LGBMClassifier(**params, verbose=-1)\n",
    "    acc = train_and_evaluate(lgbm_model, X_train_pca, y_train, X_test_pca, y_test)\n",
    "\n",
    "    print(f\"Accuracy: {acc:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uz-0BvylZHK1"
   },
   "source": [
    "### **CatBoost**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "c_nYgYgYZMR6",
    "outputId": "415d07c3-cbca-4307-c9a5-15543cced698"
   },
   "outputs": [],
   "source": [
    "print(\"Testing CatBoost with different hyperparameters:\")\n",
    "\n",
    "catboost_params_list = [\n",
    "    {\"iterations\": 100, \"learning_rate\": 0.1, \"depth\": 7, \"verbose\": False, \"random_seed\": 42},\n",
    "    {\"iterations\": 150, \"learning_rate\": 0.05, \"depth\": 9, \"verbose\": False, \"random_seed\": 42},\n",
    "    {\"iterations\": 200, \"learning_rate\": 0.1, \"depth\": 5, \"verbose\": False, \"random_seed\": 42},\n",
    "    {\"iterations\": 300, \"learning_rate\": 0.05, \"depth\": 6, \"verbose\": False, \"random_seed\": 42},\n",
    "    {\"iterations\": 250, \"learning_rate\": 0.2, \"depth\": 4, \"verbose\": False, \"random_seed\": 42},\n",
    "]\n",
    "\n",
    "for i, params in enumerate(catboost_params_list, 1):\n",
    "    print(f\"\\nSet {i}: {params}\")\n",
    "\n",
    "    catboost_model = CatBoostClassifier(**params)\n",
    "    acc = train_and_evaluate(catboost_model, X_train_pca, y_train, X_test_pca, y_test)\n",
    "\n",
    "    print(f\"Accuracy: {acc:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RBCDZGiBa3Iv"
   },
   "source": [
    "### **XGBoost**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qQRi2Gg0d6oN"
   },
   "outputs": [],
   "source": [
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "oAFZ8Gcga-4u",
    "outputId": "230fb6c6-1b6a-4cad-a2df-27ec84fd631c"
   },
   "outputs": [],
   "source": [
    "print(\"Testing XGBoost with different hyperparameters:\")\n",
    "\n",
    "xgboost_params_list = [\n",
    "    {\"n_estimators\": 100, \"learning_rate\": 0.1, \"max_depth\": 7, \"random_state\": 42, \"eval_metric\": \"logloss\"},\n",
    "    {\"n_estimators\": 150, \"learning_rate\": 0.05, \"max_depth\": 9, \"random_state\": 42, \"eval_metric\": \"logloss\"},\n",
    "    {\"n_estimators\": 200, \"learning_rate\": 0.1, \"max_depth\": 5, \"random_state\": 42, \"eval_metric\": \"logloss\"},\n",
    "    {\"n_estimators\": 300, \"learning_rate\": 0.05, \"max_depth\": 6, \"random_state\": 42, \"eval_metric\": \"logloss\"},\n",
    "    {\"n_estimators\": 250, \"learning_rate\": 0.2, \"max_depth\": 4, \"random_state\": 42, \"eval_metric\": \"logloss\"},\n",
    "]\n",
    "\n",
    "dtrain = xgb.DMatrix(X_train_pca, label=y_train)\n",
    "dtest = xgb.DMatrix(X_test_pca, label=y_test)\n",
    "\n",
    "for i, params in enumerate(xgboost_params_list, 1):\n",
    "    print(f\"\\nSet {i}: {params}\")\n",
    "\n",
    "    num_rounds = params.pop(\"n_estimators\")\n",
    "    model = xgb.train(params, dtrain, num_boost_round=num_rounds)\n",
    "\n",
    "    y_pred = model.predict(dtest)\n",
    "    y_pred = [int(pred) for pred in y_pred]\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "    print(f\"Accuracy: {accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "c2wKr41Im3jz"
   },
   "source": [
    "**Выводы:**\n",
    "\n",
    "  - **LightGBM**:\n",
    "  \n",
    "  Наилучший результат показал Набор 5 (n_estimators=250, learning_rate=0.2, max_depth=4), с точностью 0.9287.\n",
    "\n",
    "  - **CatBoost:**\n",
    "  \n",
    "  Наилучший результат показал также Набор 5 (iterations=250, learning_rate=0.2, depth=4), с точностью 0.9277.\n",
    "\n",
    "  - **XGBoost:**\n",
    "  \n",
    "  Точность XGBoost значительно ниже, чем у LightGBM и CatBoost, и наилучший результат в Наборе 5 составляет 0.5402.\n",
    "\n",
    "**Оптимальная модель**:\n",
    "\n",
    "Из всех моделей LightGBM (Набор 5) показал наилучшие результаты с точностью 0.9287, что делает его наиболее подходящим для дальнейшего использования."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4Co467Q38_Ef"
   },
   "source": [
    "## Part 2. Use hyper parameter tuning system\n",
    "\n",
    "Use [optuna](https://optuna.org/), [hyperopt](http://hyperopt.github.io/hyperopt/) or any other zero order optimizer to find optimal hyper param set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BWnzsoFSnTP2",
    "outputId": "ec8faca5-1d7f-43b6-d708-1dc2966d7d7a"
   },
   "outputs": [],
   "source": [
    "!pip install optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MkZAjIxony6H"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import optuna\n",
    "import lightgbm as lgb\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "08IZ15q18_Ef",
    "outputId": "bbe94316-898d-4763-f8f3-16982ca75cad"
   },
   "outputs": [],
   "source": [
    "X_train_opt, X_val_opt, y_train_opt, y_val_opt = train_test_split(X_train_pca, y_train, test_size=0.2, random_state=42)\n",
    "\n",
    "# Функция оптимизации для Optuna\n",
    "def objective(trial):\n",
    "    params = {\n",
    "        'boosting_type': 'gbdt',\n",
    "        'num_leaves': trial.suggest_int('num_leaves', 31, 256),\n",
    "        'max_depth': trial.suggest_int('max_depth', 3, 12),\n",
    "        'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.3),\n",
    "        'n_estimators': trial.suggest_int('n_estimators', 50, 500),\n",
    "        'min_child_samples': trial.suggest_int('min_child_samples', 10, 100),\n",
    "        'subsample': trial.suggest_float('subsample', 0.5, 1.0),\n",
    "        'colsample_bytree': trial.suggest_float('colsample_bytree', 0.5, 1.0),\n",
    "    }\n",
    "\n",
    "    model = lgb.LGBMClassifier(**params, verbose=-1)\n",
    "    model.fit(X_train_opt, y_train_opt)\n",
    "\n",
    "    y_pred = model.predict(X_val_opt)\n",
    "    accuracy = accuracy_score(y_val_opt, y_pred)\n",
    "\n",
    "    return accuracy\n",
    "\n",
    "study = optuna.create_study(direction=\"maximize\")\n",
    "study.optimize(objective, n_trials=50)\n",
    "\n",
    "print(f\"Best parameters: {study.best_params}\")\n",
    "print(f\"Best accuracy: {study.best_value:.4f}\")\n",
    "\n",
    "df_trials = pd.DataFrame(study.trials_dataframe())\n",
    "df_trials_sorted = df_trials.sort_values(by=\"value\", ascending=False)\n",
    "\n",
    "print(\"\\nDetailed results of all trials (sorted by accuracy):\")\n",
    "print(df_trials_sorted[['number', 'value',\n",
    "                        'params_num_leaves',\n",
    "                        'params_max_depth',\n",
    "                        'params_learning_rate',\n",
    "                        'params_n_estimators',\n",
    "                        'params_min_child_samples',\n",
    "                        'params_subsample',\n",
    "                        'params_colsample_bytree']].head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WIcDxJ6_8_Ef"
   },
   "source": [
    "### Conclusion\n",
    "\n",
    "Please, write down your thoughts on the experiment results:\n",
    "\n",
    "\n",
    "**Лучшие параметры:**  \n",
    "- `num_leaves`: **117**  \n",
    "- `max_depth`: **4**  \n",
    "- `learning_rate`: **0.1533**  \n",
    "- `n_estimators`: **364**  \n",
    "- `min_child_samples`: **89**  \n",
    "- `subsample`: **0.7953**  \n",
    "- `colsample_bytree`: **0.5286**  \n",
    "\n",
    "**Лучшая accuracy:** **97.55%**\n",
    "\n",
    "**Вывод:**\n",
    "\n",
    "Модель показала высокую accuracy, что свидетельствует о хорошем подборе гиперпараметров. Умеренная глубина деревьев и размер листьев позволили избежать переобучения, а комбинация параметров `learning_rate` и `n_estimators` обеспечила баланс между скоростью обучения и качеством."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NSXPNEME8_Ef"
   },
   "source": [
    "## Part 3. Interpret the model predictions\n",
    "\n",
    "Please use [shap](https://github.com/slundberg/shap) to build some plots and try to interpret them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vpRlpU_IwdLC",
    "outputId": "cda18de0-1188-4185-b7df-45f3d7139412"
   },
   "outputs": [],
   "source": [
    "!pip install shap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aRNaYuo88_Eg"
   },
   "outputs": [],
   "source": [
    "import shap  # noqa: F401"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6yQbTvNDwjar"
   },
   "source": [
    "Сохраним лучшую модель из части 2:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 132
    },
    "id": "uw0wcIxtwqQR",
    "outputId": "c9ee36bb-0917-4afa-ca5b-bd1b8c7fe7f5"
   },
   "outputs": [],
   "source": [
    "best_model_params = study.best_params\n",
    "best_model = lgb.LGBMClassifier(**best_model_params, verbose=-1)\n",
    "best_model.fit(X_train_opt, y_train_opt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "P7fFSvzvw69s"
   },
   "source": [
    "SHAP Explainer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-J66Bzv9w14c"
   },
   "outputs": [],
   "source": [
    "explainer = shap.Explainer(best_model)\n",
    "shap_values = explainer.shap_values(X_test_pca)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rYCNmRv-yiAz"
   },
   "source": [
    "Проверим количество классов:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5NSVFHy-yiZ0",
    "outputId": "cef1d77d-6408-4ced-f361-0e494f7c47b9"
   },
   "outputs": [],
   "source": [
    "num_classes = shap_values.shape[1] if len(shap_values.shape) > 2 else 1\n",
    "print(\"Распознанное количество классов:\", num_classes)\n",
    "\n",
    "shap_values_mean = shap_values.mean(axis=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WjrdBre6yUmk"
   },
   "source": [
    "Глобальная важность признаков:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 995
    },
    "id": "UdknoAz7yYNc",
    "outputId": "a8fd05ec-3847-468b-92ce-2b5bd8cb043b"
   },
   "outputs": [],
   "source": [
    "print(\"Summary Plot (Bar) - Averaged SHAP values across classes\")\n",
    "shap.summary_plot(shap_values_mean, X_test_pca, plot_type=\"bar\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CvW7roKyy4bj"
   },
   "source": [
    "Распределение значений SHAP:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 995
    },
    "id": "dJBEs7d5y8bO",
    "outputId": "f835c3b0-38cc-455d-e153-2115ddb2db2b"
   },
   "outputs": [],
   "source": [
    "print(\"Summary Plot (Distribution) - Averaged SHAP values across classes\")\n",
    "shap.summary_plot(shap_values_mean, X_test_pca)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WDuG0xH_zAIx"
   },
   "source": [
    "Влияние конкретного признака на предсказания:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 488
    },
    "id": "C2v0J6-Vy_P5",
    "outputId": "93be9695-5737-4426-a4eb-38e070161c7b"
   },
   "outputs": [],
   "source": [
    "feature_to_plot = 0  # Можно заменить на индекс интересующего признака\n",
    "print(f\"Dependence Plot - Feature {feature_to_plot} - Averaged SHAP values\")\n",
    "shap.dependence_plot(feature_to_plot, shap_values_mean, X_test_pca)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "u2isgdQezO4O"
   },
   "source": [
    "Индивидуальное объяснение для одного примера:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 211
    },
    "id": "61WbmBMmzRya",
    "outputId": "7e03bf99-bf70-40a3-8b0e-70dfb9a8da83"
   },
   "outputs": [],
   "source": [
    "sample_index = 0  # Можно заменить на индекс интересующего признака\n",
    "print(f\"Force Plot for example {sample_index} - Averaged SHAP values\")\n",
    "shap.initjs()\n",
    "expected_value_mean = np.mean(explainer.expected_value)\n",
    "shap.force_plot(expected_value_mean, shap_values_mean[sample_index], X_test_pca[sample_index])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hKGqgCij8_Eg"
   },
   "source": [
    "### Conclusion\n",
    "\n",
    "Your thoughts about the plots and model behaviour:\n",
    "\n",
    "1. **Ключевые признаки**:  \n",
    "   Feature 0 оказался самым значимым для модели, с большим отрывом по важности. За ним следуют Feature 3, Feature 4, Feature 1 и Feature 2. Их влияние подтверждает сильную зависимость целевой переменной от этих признаков.\n",
    "\n",
    "2. **Глобальная интерпретация**:  \n",
    "   Распределение SHAP-значений показало наличие кластеров данных и сложных нелинейных зависимостей. Feature 0 особенно выделяется своей ключевой ролью в определении результата модели.\n",
    "\n",
    "3. **Локальная интерпретация**:  \n",
    "   Индивидуальные объяснения для конкретных наблюдений (Force Plot) помогают понять, какие признаки вносят наибольший вклад в предсказания. Dependence Plot для Feature 0 выявил сложные зависимости, которые модель эффективно улавливает.\n",
    "\n",
    "4. **Заключение**:  \n",
    "   Модель демонстрирует стабильное поведение с интерпретируемыми результатами. Однако важность Feature 0 требует дополнительного анализа, чтобы понять его влияние в контексте задачи."
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "celltoolbar": "Create Assignment",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
