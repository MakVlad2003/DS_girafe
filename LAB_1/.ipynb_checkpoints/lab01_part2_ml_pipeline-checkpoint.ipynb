{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "P8fIX_Up9yQo",
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-86e0de040aac317a",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "source": [
    "# Lab assignment №1, part 2\n",
    "\n",
    "This lab assignment consists of several parts. You are supposed to make some transformations, train some models, estimate the quality of the models and explain your results.\n",
    "\n",
    "Several comments:\n",
    "* Don't hesitate to ask questions, it's a good practice.\n",
    "* No private/public sharing, please. The copied assignments will be graded with 0 points.\n",
    "* Blocks of this lab will be graded separately."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MwIo0sgg9yQs"
   },
   "source": [
    "__*This is the second part of the assignment. First and third parts are waiting for you in the same directory.*__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MU-p69Lc9yQs",
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-512ba712fc0fc065",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "source": [
    "## Part 2. Data preprocessing, model training and evaluation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9f3PXkl_9yQt",
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-b656a4266174b009",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "source": [
    "### 1. Reading the data\n",
    "Today we work with the [dataset](https://archive.ics.uci.edu/ml/datasets/Statlog+%28Vehicle+Silhouettes%29), describing different cars for multiclass ($k=4$) classification problem. The data is available below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8zfjcKcX9yQt",
    "outputId": "1c9e347d-cdb3-4071-8872-2ed9911b2f10"
   },
   "outputs": [],
   "source": [
    "!pip install ucimlrepo\n",
    "!pip install scikit-plot\n",
    "!pip install --upgrade scikit-plot\n",
    "!pip install scipy==1.7.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lPymH-LB9yQu"
   },
   "outputs": [],
   "source": [
    "import ucimlrepo as uci\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Nm0n5DEq9yQv",
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-eebac6bfdf73d0bc",
     "locked": true,
     "schema_version": 2,
     "solution": false
    },
    "outputId": "478e281d-f8d2-4e1b-d160-b6aaec85d4e7"
   },
   "outputs": [],
   "source": [
    "dataset = uci.fetch_ucirepo(id=149)\n",
    "\n",
    "print(dataset.metadata.name, '\\n')\n",
    "print(dataset.metadata.abstract, '\\n')\n",
    "print(dataset.metadata.additional_info.summary, '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "k_suMVWTgO65",
    "outputId": "6f3fb29e-a835-420a-8c3d-5b4d41c923b5"
   },
   "outputs": [],
   "source": [
    "# При дальгейшем обучении было выяснено, что дата содержит Nan-ы.\n",
    "# Исправим это, заменив Nan на среднее по столбцам\n",
    "data = dataset.data.features\n",
    "data = data.fillna(data.median())\n",
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "z-NKJuW2Dlwt"
   },
   "outputs": [],
   "source": [
    "# Далее при обучении было выяснено, что затесался импостер в виде класса 204.\n",
    "# Удалим его, чтоб жизнь не портил...\n",
    "\n",
    "target = dataset.data.targets\n",
    "\n",
    "# Исключение строк, где target равен '204'\n",
    "mask = target['class'] != '204'\n",
    "data_filtered = data[mask].reset_index(drop=True)\n",
    "target_filtered = target[mask].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Zfi7QZrC9yQw",
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-eebac6bfdf73d0bc",
     "locked": true,
     "schema_version": 2,
     "solution": false
    },
    "outputId": "c3e5aeda-895b-4b61-ad54-8cf696d3c7bc"
   },
   "outputs": [],
   "source": [
    "print(data.shape, target.shape)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(data_filtered, target_filtered, test_size=0.35)\n",
    "print(X_train.shape, y_train.shape, X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "a_0cRmQgZA8I",
    "outputId": "123490fa-e4ee-43f7-e4f8-d137de7ebc00"
   },
   "outputs": [],
   "source": [
    "print(f\"Уникальные классы после фильтрации в y_train: {y_train['class'].unique()}\")\n",
    "print(f\"Уникальные классы после фильтрации в y_test: {y_test['class'].unique()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "anN2oL_p9yQw",
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-88b1a0f688568f2c",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "source": [
    "To get some insights about the dataset, `pandas` might be used. The `train` part is transformed to `pd.DataFrame` below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 572
    },
    "id": "UwJVjBSN9yQx",
    "outputId": "0a2940a8-ca06-44ac-ecda-bcc482c73f68"
   },
   "outputs": [],
   "source": [
    "X_train_pd = pd.DataFrame(X_train)\n",
    "\n",
    "# First 15 rows of our dataset.\n",
    "X_train_pd.head(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5bie-0aI9yQx",
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-98e7d91d77d65fcf",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "source": [
    "Methods `describe` and `info` deliver some useful information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 390
    },
    "id": "VV2Li0DL9yQx",
    "outputId": "d4d4e2e4-d040-41ec-89c9-90061ba63f7e"
   },
   "outputs": [],
   "source": [
    "X_train_pd.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wZuVh6f_9yQx",
    "outputId": "cab24e49-abcc-486e-d1ec-fafc79b60bce"
   },
   "outputs": [],
   "source": [
    "X_train_pd.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7rJYpqYt9yQy",
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-be844269be69c387",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "source": [
    "### 2. Machine Learning pipeline\n",
    "Here you are supposed to perform the desired transformations. Please, explain your results briefly after each task."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5H-pc9-v9yQy"
   },
   "source": [
    "#### 2.0. Data preprocessing\n",
    "* Make some transformations of the dataset (if necessary). Briefly explain the transformations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "a90n6OGL9yQy",
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-a1514aa189a49fca",
     "locked": false,
     "points": 15,
     "schema_version": 2,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "t5_gfXr_OMKh"
   },
   "source": [
    "Для улучшения работы моделей необходимо нормализовать данные, чтобы предотвратить слишком большие значения весов, а также для эффективного выполнения PCA."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EJqQaw909yQy"
   },
   "source": [
    "#### 2.1. Basic logistic regression\n",
    "* Find optimal hyperparameters for logistic regression with cross-validation on the `train` data (small grid/random search is enough, no need to find the *best* parameters).\n",
    "\n",
    "* Estimate the model quality with `f1` and `accuracy` scores.\n",
    "* Plot a ROC-curve for the trained model. For the multiclass case you might use `scikitplot` library (e.g. `scikitplot.metrics.plot_roc(test_labels, predicted_proba)`).\n",
    "\n",
    "*Note: please, use the following hyperparameters for logistic regression: `multi_class='multinomial'`, `solver='saga'` `tol=1e-3` and ` max_iter=500`.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nHFKPd0j9yQy"
   },
   "outputs": [],
   "source": [
    "# You might use this command to install scikit-plot.\n",
    "# Warning, if you a running locally, don't call pip from within jupyter, call it from terminal in the corresponding\n",
    "# virtual environment instead"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9CyPs3ZnOmcu"
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sJ68flRx9yQy",
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-1dd5ad5d0845cbbb",
     "locked": false,
     "points": 5,
     "schema_version": 2,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "estimator = LogisticRegression(penalty='elasticnet',\n",
    "                               multi_class='multinomial',\n",
    "                               solver='saga',\n",
    "                               tol=1e-3, max_iter=500,\n",
    "                               random_state=42)\n",
    "\n",
    "param_grid = {\n",
    "    'l1_ratio': np.linspace(0, 1, 51),\n",
    "    'C': np.logspace(-1, 2, 50)\n",
    "  }\n",
    "\n",
    "logreg_gridsearch = GridSearchCV(estimator, param_grid, scoring='f1_macro', n_jobs=-1, cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 225
    },
    "id": "zXObcEiZhkaP",
    "outputId": "deeb5118-c418-449d-b1dc-133363dc7618"
   },
   "outputs": [],
   "source": [
    "logreg_gridsearch.fit(X_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ALWQZXBqOzg3",
    "outputId": "74d53ff9-cc4e-4cc9-bbbc-6d5f0e2e136c"
   },
   "outputs": [],
   "source": [
    "print(f'Лучшие гиперпараметры: {logreg_gridsearch.best_params_}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Aw_yGBD3QclT",
    "outputId": "e39b0c0a-f3b5-49f4-a47f-b3ae94c8a57e"
   },
   "outputs": [],
   "source": [
    "import sklearn.metrics as metr\n",
    "\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "accuracy = metr.accuracy_score(y_test, logreg_gridsearch.predict(X_test_scaled))\n",
    "f1 = metr.f1_score(y_test, logreg_gridsearch.predict(X_test_scaled), average='macro')\n",
    "\n",
    "print(f'Accuracy: {accuracy}')\n",
    "print(f'F1-score: {f1}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 489
    },
    "id": "-uKpAtAoeGij",
    "outputId": "01a2b30a-3e41-4e90-8a81-55cecfe32df7"
   },
   "outputs": [],
   "source": [
    "from scikitplot.metrics import plot_roc\n",
    "\n",
    "plot_roc(y_test, logreg_gridsearch.predict_proba(X_test_scaled))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0lWMNs2q4VGy"
   },
   "source": [
    "Для логистической регрессии результат довольно хороший. Судя по ROC-кривым, модель уверенно справляется с классами **bus** и **van**, однако для классов **saab** и **opel** предсказания оказываются менее точными."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Td7C1nrb9yQy"
   },
   "source": [
    "#### 2.2. PCA: explained variance plot\n",
    "* Apply the PCA to the train part of the data. Build the explaided variance plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SSpPpQZA9yQz",
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-c6c614740bce090e",
     "locked": false,
     "points": 10,
     "schema_version": 2,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 80
    },
    "id": "nNCRUoXVhqXl",
    "outputId": "1cca7463-2ec4-4b32-8fb6-81fa4ad9a3fd"
   },
   "outputs": [],
   "source": [
    "pca = PCA()\n",
    "pca.fit(X_train_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 487
    },
    "id": "h9-dF6XAhs_3",
    "outputId": "c1746b5d-9c16-4e98-a23b-11508dd0db17"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 5))\n",
    "\n",
    "explained_variance_ratio = np.cumsum(pca.explained_variance_ratio_)\n",
    "plt.plot(np.arange(1, X_train.shape[1] + 1), explained_variance_ratio, marker='o')\n",
    "\n",
    "plt.xlabel('Number of components')\n",
    "plt.ylabel('Cumulative explained variance ratio')\n",
    "plt.title('Explained Variance by PCA Components')\n",
    "\n",
    "plt.grid()\n",
    "\n",
    "# Просто для красоты добавим:\n",
    "\n",
    "# Меток для каждого компонента\n",
    "for i, evr in enumerate(explained_variance_ratio):\n",
    "    plt.text(i+1, evr, f'{evr:.2f}', ha='center', va='bottom')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "H6nEM5uk9yQz",
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-0c1fe666f52fe53c",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "source": [
    "#### 2.3. PCA trasformation\n",
    "* Select the appropriate number of components. Briefly explain your choice. Should you normalize the data?\n",
    "\n",
    "*Use `fit` and `transform` methods to transform the `train` and `test` parts.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sY4FdR6_9yQz",
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-96ab18d96473ef71",
     "locked": false,
     "points": 5,
     "schema_version": 2,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "n_components = 17\n",
    "opt_pca = PCA(n_components=n_components)\n",
    "\n",
    "X_train_components = opt_pca.fit_transform(X_train_scaled)\n",
    "X_test_components = opt_pca.transform(X_test_scaled)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4OTuW4P1rt4G"
   },
   "source": [
    "Я выбрал 17 компонент, чтобы с одной стороны уменьшить размерность данных, но при этом сохранить почти 100% объясненной дисперсии."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GE2Hrm179yQz"
   },
   "source": [
    "**Note: From this point `sklearn` [Pipeline](https://scikit-learn.org/stable/modules/compose.html) might be useful to perform transformations on the data. Refer to the [docs](https://scikit-learn.org/stable/modules/generated/sklearn.pipeline.Pipeline.html) for more information.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "W7lawG2C9yQz",
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-d28b58a35c94e988",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "source": [
    "#### 2.4. Logistic regression on PCA-preprocessed data.\n",
    "* Find optimal hyperparameters for logistic regression with cross-validation on the transformed by PCA `train` data.\n",
    "\n",
    "* Estimate the model quality with `f1` and `accuracy` scores.\n",
    "* Plot a ROC-curve for the trained model. For the multiclass case you might use `scikitplot` library (e.g. `scikitplot.metrics.plot_roc(test_labels, predicted_proba)`).\n",
    "\n",
    "*Note: please, use the following hyperparameters for logistic regression: `multi_class='multinomial'`, `solver='saga'` and `tol=1e-3`*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 225
    },
    "id": "FsVh48Qvi8Vq",
    "outputId": "2e23234f-812c-464c-fc54-fa21ac8bd0fe"
   },
   "outputs": [],
   "source": [
    "comp_scaler = StandardScaler()\n",
    "X_train_comp_scaled = comp_scaler.fit_transform(X_train_components)\n",
    "\n",
    "estimator = LogisticRegression(penalty='elasticnet',\n",
    "                               multi_class='multinomial',\n",
    "                               solver='saga',\n",
    "                               tol=1e-3,\n",
    "                               random_state=42,\n",
    "                               max_iter=1000)\n",
    "\n",
    "param_grid = {\n",
    "    'class_weight': [None, 'balanced'],\n",
    "    'l1_ratio': np.linspace(0, 1, 41),\n",
    "    'warm_start': [True, False, ]\n",
    "  }\n",
    "\n",
    "logreg_gridsearch = GridSearchCV(estimator, param_grid, scoring='f1_macro', n_jobs=-1, cv=7)\n",
    "logreg_gridsearch.fit(X_train_comp_scaled, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8P4JtfIX6D-T",
    "outputId": "4e5e0930-199e-4314-9b22-c1fbb7aa1317"
   },
   "outputs": [],
   "source": [
    "print(\"Лучшие гиперпараметры:\", logreg_gridsearch.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ro8yoAZt6Nr1",
    "outputId": "0cb9a2e2-61d3-4500-bfa9-ee9991554742"
   },
   "outputs": [],
   "source": [
    "import sklearn.metrics as metr\n",
    "\n",
    "X_test_comp_scaled = comp_scaler.transform(X_test_components)\n",
    "y_pred = logreg_gridsearch.predict(X_test_comp_scaled)\n",
    "\n",
    "accuracy = metr.accuracy_score(y_test, y_pred)\n",
    "f1 = metr.f1_score(y_test, y_pred, average='macro')\n",
    "\n",
    "print('Accuracy:', accuracy)\n",
    "print('F1 Score:', f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 489
    },
    "id": "Pf7Kj0_wjqZ2",
    "outputId": "e9c6db1b-1722-43be-8453-422ac76937ca"
   },
   "outputs": [],
   "source": [
    "plot_roc(y_test, logreg_gridsearch.predict_proba(comp_scaler.transform(X_test_components)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ANBQuFbR6c-F"
   },
   "source": [
    "При обучении модели на признаках, полученных после PCA, значения метрик точности и F1 увеличились примерно на 0.04, а ROC AUC также показал рост. Теперь модель почти с 100% уверенностью предсказывает класс **van**!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pMlpempN9yQz",
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-99191c0852538d4d",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "source": [
    "#### 2.8. Learning curve\n",
    "Your goal is to estimate, how does the model behaviour change with the increase of the `train` dataset size.\n",
    "\n",
    "* Split the training data into 10 equal (almost) parts. Then train the models from above (Logistic regression, Desicion Tree, Random Forest) with optimal hyperparameters you have selected on 1 part, 2 parts (combined, so the train size in increased by 2 times), 3 parts and so on.\n",
    "\n",
    "* Build a plot of `accuracy` and `f1` scores on `test` part, varying the `train` dataset size (so the axes will be score - dataset size.\n",
    "\n",
    "* Analyse the final plot. Can you make any conlusions using it?\n",
    "\n",
    "Tip: there's a function in sklern to do that"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4Wfetb20iU7M"
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import learning_curve\n",
    "\n",
    "from tqdm.auto import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dFBDOB529yQ0"
   },
   "outputs": [],
   "source": [
    "logreg_params = {\n",
    "    'multi_class' : 'multinomial',\n",
    "    'solver' : 'saga',\n",
    "    'penalty' : 'elasticnet',\n",
    "    'max_iter' : 1000,\n",
    "    'class_weight' : 'balanced',\n",
    "    'l1_ratio' : 0.1\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YeIlXodqiM74"
   },
   "outputs": [],
   "source": [
    "models = [LogisticRegression(**logreg_params),\n",
    "          DecisionTreeClassifier(max_depth=5),\n",
    "          RandomForestClassifier(n_estimators=100)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XPGNjFznjw3Y"
   },
   "outputs": [],
   "source": [
    "split_size = X_train.shape[0] // 10\n",
    "\n",
    "accs = [[], [], []]\n",
    "f1s  = [[], [], []]\n",
    "sizes = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000,
     "referenced_widgets": [
      "846eebc6fa494235b303e6cde94a8dab",
      "f841772d2aa3442ea72c4f521188768c",
      "01207ff4668b42bfaa49930ab8b4da85",
      "4a374ec59d54454091f34debc873dd7a",
      "5c948ccc90ed4fe6a680235fb6410c18",
      "ccb870e31f934b57a67c52a522f90a63",
      "bf1c7775dc4c427d8e47fe4c1c95f3fc",
      "4fde77a400f34d1f9e87c5cb252ef8a4",
      "003e7f81c5344d31bd056f8a3faab45b",
      "f7c04f1ece0a44e4af4ea749bc7edc69",
      "a5daf6f237294433918dd563ae16f439"
     ]
    },
    "id": "NkfrmuAZiQWF",
    "outputId": "dd044b42-f8e8-4d9a-cf9d-0ec1ccd6ad13"
   },
   "outputs": [],
   "source": [
    "for i in tqdm(range(1, 11)):\n",
    "    if i==10:\n",
    "        X_subtrain = X_train_comp_scaled\n",
    "        y_subtrain = y_train\n",
    "    else:\n",
    "        X_subtrain = X_train_comp_scaled[:i*split_size]\n",
    "        y_subtrain = y_train[:i*split_size]\n",
    "    sizes.append(X_subtrain.shape[0])\n",
    "\n",
    "    for j, model in enumerate(models):\n",
    "        model.fit(X_subtrain, y_subtrain)\n",
    "        pred = model.predict(X_test_comp_scaled)\n",
    "        accs[j].append(metr.accuracy_score(y_test, pred))\n",
    "        f1s[j].append(metr.f1_score(y_test, pred, average='macro'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 487
    },
    "id": "4bhrLfE4iicQ",
    "outputId": "1a1dfb38-ce34-4395-8b81-6b8298410aa6"
   },
   "outputs": [],
   "source": [
    "names = ['Logistic Regression', 'Decision Tree', 'Random Forest']\n",
    "fig, axs = plt.subplots(ncols=2, figsize=(15, 5))\n",
    "\n",
    "axs[0].set_title('Accuracy')\n",
    "for i in range(3):\n",
    "    axs[0].plot(sizes, accs[i], label=names[i])\n",
    "\n",
    "axs[0].legend()\n",
    "axs[0].set_xlabel('Number of training observations')\n",
    "axs[0].grid()\n",
    "\n",
    "axs[1].set_title('F1')\n",
    "for i in range(3):\n",
    "    axs[1].plot(sizes, f1s[i], label=names[i])\n",
    "\n",
    "axs[1].legend()\n",
    "axs[1].set_xlabel('Number of training observations')\n",
    "axs[1].grid()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6u56SGRPip8U"
   },
   "source": [
    "1. Первое, что бросается в глаза: логистическая регрессия и случайный лес показывают хорошие результаты, а вот решающее дерево явно отстает.\n",
    "\n",
    "2. Для логистической регрессии наблюдается практически монотонный рост качества с увеличением объема обучающей выборки. Это говорит о том, что для этой модели больше данных — лучше (по крайней мере, в этом диапазоне и на данном наборе данных).\n",
    "\n",
    "3. В случае случайного леса видно, что модель достигает насыщения: после определенного объема данных качество перестает заметно улучшаться.\n",
    "\n",
    "4. С решающим деревом картина похожа на случайный лес, но есть ощущение, что качество сначала растет, а затем начинает немного падать. Возможно, это просто случайные колебания модели, и для более точного вывода следовало бы провести несколько перезапусков экспериментов."
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Create Assignment",
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
